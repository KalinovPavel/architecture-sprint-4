# Мониторинг

Ниже описан план, как будем выстраивать систему мониторинга в компании «Александрит», зачем это нужно и как это повлияет на бизнес.

---
## 1. Мотивация

В настоящее время компания «Александрит» собирает данные только через Яндекс Метрику, но этого недостаточно. С открытием API для партнёров у нас сильно выросло количество заказов, а также возросла вероятность проблем в интеграциях, связанных с RabbitMQ, CRM и MES. Без наблюдаемости (observability) мы не можем точно ответить на вопросы:

- Почему «подвисают» или теряются заказы?
- Как система работает под растущей нагрузкой и какие есть узкие места?
- Как быстро наши сервисы реагируют на запросы?
- Почему у клиентов разные задержки при одинаковых операциях?

Мониторинг позволит:
- **Сократить время на поиск и диагностику ошибок**. Сразу видеть, где «пробка» – в API, в RabbitMQ, в базе или в MES.
- **Повысить качество обслуживания**: своевременно выявлять узкие места и масштабировать компоненты.
- **Обеспечить SLA и избежать репутационных потерь**: получать алерты и предупреждения о проблемах раньше, чем их заметят клиенты.
- **Приоритизировать улучшения**: иметь объективные данные о том, где мы теряем производительность и какие изменения дают наибольший эффект.

Для бизнеса это означает снижение затрат на «пожарную» работу над инцидентами, уменьшение количества жалоб клиентов и, как следствие, рост прибыли и лояльности.

---
## 2. Выбор подхода к мониторингу

Система «Александрит» состоит из нескольких ключевых компонентов: интернет-магазина (Shop API), CRM, MES и брокера сообщений (RabbitMQ). У каждого компонента своя специфика и метрики.

Мы можем использовать **«четыре золотых сигнала»** (latency, traffic, errors, saturation) для основных HTTP-сервисов (Shop, CRM, MES), чтобы охватить:
- **Latency**: время ответа API
- **Traffic**: количество запросов (RPS)
- **Errors**: коды ошибок (5xx, 4xx)
- **Saturation**: загрузка CPU, памяти, а также заполненность очередей

Для RabbitMQ и баз данных дополнительно можно применить некоторые приёмы из подхода **USE (Utilization, Saturation, Errors)**:
- **Utilization**: сколько ресурсов используется (CPU, RAM, диски, соединения)
- **Saturation**: насколько очереди загружены
- **Errors**: сбои, переполненные очереди, dead-letter-сообщения

Таким образом, мы комбинируем «четыре золотых сигнала» для сервисов и «USE» для более низкоуровневых ресурсов (БД, очередь).

---
## 3. Метрики для отслеживания

Ниже описаны основные метрики, которые планируем собирать. Для каждой метрики укажем, зачем она нужна и какие метки могут быть полезны.

### 3.1 RabbitMQ
1. **Number of dead-letter-exchange letters**  
   - **Зачем**: показывает, сколько сообщений отбрасывается из основной очереди. Рост этого показателя может указывать на ошибки в потребителях (MES, CRM) или неправильную маршрутизацию.
   - **Метки**: имя очереди, сервис-отправитель.
2. **Number of messages in flight**  
   - **Зачем**: показывает, сколько сообщений в очереди обрабатывается в данный момент. Если это число стабильно высокое, значит потребители не справляются с нагрузкой.
   - **Метки**: имя очереди, тип сообщения.

### 3.2 API-сервисы (Shop, CRM, MES)
1. **Number of requests (RPS)**  
   - **Зачем**: измерение «Traffic» из «четырёх сигналов». Позволяет понять общую загрузку сервиса.
   - **Метки**: метод запроса (GET, POST и т.д.), код статуса (200, 404, 500).
2. **Response time (latency)**  
   - **Зачем**: ключевой показатель для SLA и удобства пользователей. Если время ответа растёт, нужна оптимизация.
   - **Метки**: URL-эндпоинт (по группам), код статуса.
3. **Number of HTTP 500**  
   - **Зачем**: показывает количество критических ошибок на бэкенде. Рост – признак серьёзных проблем.
   - **Метки**: имя сервиса (Shop, CRM, MES), эндпоинт.
4. **CPU %** (для Shop, CRM, MES)  
   - **Зачем**: при загрузке CPU выше порога (80-90%) сервис может не успевать обрабатывать запросы.
   - **Метки**: имя сервиса, окружение (dev/release/prod), регион.
5. **Memory Utilization** (для Shop, CRM, MES)  
   - **Зачем**: при нехватке памяти может происходить OOM killer, сбои.
   - **Метки**: имя сервиса, окружение.

### 3.3 Базы данных (Shop DB, MES DB)
1. **Number of connections**  
   - **Зачем**: важно понимать, не исчерпываем ли мы пул соединений. Если соединений слишком много, возможно утечки.
   - **Метки**: имя базы, хост.
2. **Memory Utilisation**  
   - **Зачем**: при перегрузке памяти в БД запросы становятся медленнее, может произойти деградация.
   - **Метки**: окружение.
3. **Size of DB instance**  
   - **Зачем**: контроль за ростом объёма базы, особенно если используется один инстанс.
   - **Метки**: название схемы (Shop, MES).

### 3.4 Хранилище (S3)
- **Size of S3 storage**  
  - **Зачем**: контролировать, насколько быстро растёт объём загружаемых 3D-моделей.
  - **Метки**: окружение.

При необходимости можно добавить метрики «Number of simultanious sessions», «Kb transferred» и т.д., но вышеуказанные — основные для быстрого старта.

---
## 4. План действий

1. **Выбор инструмента мониторинга и развёртывание time-series базы**  
   - Рассмотреть Prometheus + Grafana (самый распространённый стек). Как вариант, использовать Yandex Managed Service for Prometheus.
2. **Настройка агентов и экспортеров**  
   - Для сервисов на Java, C# и Vue: использовать готовые библиотеки (Micrometer, OpenTelemetry) для метрик.
   - Для RabbitMQ: настроить RabbitMQ Exporter.
   - Для баз данных: использовать PostgreSQL/MySQL exporter (в зависимости от используемой СУБД).
3. **Конфигурация дашбордов и алертинга**  
   - Создать дашборды в Grafana, отразить ключевые метрики (RPS, ошибки, latency, CPU, память, очередь).
   - Настроить оповещения (e-mail, Telegram) при превышении пороговых значений.
4. **Проверка и тестирование**  
   - Провести нагрузочное тестирование (например, JMeter, Locust), чтобы убедиться, что метрики собираются корректно и алерты срабатывают.
5. **Обучение команды и внедрение**  
   - Провести сессию для разработчиков и админов, как смотреть дашборды и реагировать на алерты.
6. **Расширение набора метрик**  
   - По мере появления новых проблем или сервисов добавлять дополнительные метрики и улучшать дашборды.

---
## 5. Показатели насыщенности (thresholds)

### 5.1 Принципы выбора пороговых значений
- Используем общепринятые best-practices (80-90% для CPU/Memory).
- Для времени ответа — учитываем договорённый SLA (например, < 200 мс для внутренних сервисов, < 1 с для публичных).
- Для очередей — порог в зависимости от пропускной способности: например, если в очереди RabbitMQ > 1000 сообщений, это может означать потенциальное отставание.

### 5.2 Действия при превышении порога
- **CPU / Memory**: при достижении 80-90% генерируется предупреждение. Если загруженность не спадает, автоматически создаётся тикет на масштабирование.
- **Response time**: если среднее время ответа API превышает X мс в течение определённого интервала, система отправляет алерт в мессенджер и на e-mail ответственных.
- **Dead-letter messages**: если количество dead-letter-сообщений резко растёт, поднимается инцидент в системе Service Desk (как вариант) и алерт в DevOps.
- **Queue length**: если очередь переполнена (свыше заданного порога), возможно «автоскейлинг» потребителей (воркеров) или перепланировка задач.

Таким образом, внедрённая система мониторинга позволит видеть общее состояние системы, быстро находить корневые причины проблем и своевременно масштабироваться при росте нагрузки. Для бизнеса это означает более стабильную работу, предсказуемость SLA и снижение репутационных рисков.


